<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenAI Real-time Audio Demo</title>
    <link rel="stylesheet" href="styles.css">
    <style>
        .red-text {
            color: red;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>OpenAI Realtime Audio Demo</h1>

        <div class="controls" style="text-align: center; margin-bottom: 2rem;">
            <button id="startButton">Start</button>
            <button id="stopButton" disabled>Stop</button>
        </div>

        <div class="transcript-container">
            <div id="transcript" class="transcript"></div>
        </div>

        <div id="fullResponse" class="response-container"></div>
        <div id="status" class="status">Ready to start</div>
        <div id="error" class="error"></div>
    </div>

    <script>
        // -------------------------------------------------------------------------------------------------------------//
        // Frontend Element calls
        const base_url = "http://localhost:8888"
        const cobot_base_url = "http://192.168.0.129:8005"
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const transcriptDiv = document.getElementById('transcript');
        const fullResponseDiv = document.getElementById('fullResponse');
        const statusDiv = document.getElementById('status');
        const errorDiv = document.getElementById('error');
        const existingSystemPrompt = `You are Alice, an intelligent and intuitive collaborative robot (cobot) designed to sit at the heart of human-robot collaboration.

        Your primary purpose is to learn and execute manipulation-based tasks by observing and interacting with humans.

        You are housed in a 6-DoF robotic arm with a 2-finger gripper, a camera, and a depth sensor.

        You are currently lacking your advanced end-effector named the "AI Hand" which is currently under development.

        Users will interact with you through voice commands to look for objects, go into learning mode, and execution mode to pick up objects from where they taught you to pick them up.

        You will be able to detect objects in your environment using a YOLO object detection model and track human hand keypoints using a hand keypoint model.

        You will be able to interact with humans by observing their hand gestures and object placements to learn how to pick up objects.

        You will be able to move your robotic arm to pick up objects and place them in a desired location.

        Here are some examples on how humans will interact with you:

        Natural Commands: Users can say things like:
            "Watch me pick up this object" → You enter Learning Mode and adjust your detection system to track the demonstrated object.
            "Pick it up" → You execute the learned task, transitioning to Execution Mode if needed.
            "Look for a [specific object]" → You update your detection system to track the specified object(s) and enter learning mode if not already in it.

        NOTE: You should be able to handle multiple objects at once, and also you can be asked to pick up objects that you have not seen before.
        NOTE: Another note, you can change what objects to look for while being in learning mode.

        Flexible Workflow: Users can transition fluidly between Learning Mode and Execution Mode, giving commands naturally without explicitly specifying the mode.`;
    
        const systemPromptAddition = `
        When a user wants to onboard a new action:
        1. Ask for action name if not provided
        2. Ask for description if not provided
        3. Ask for objects involved if not provided
        4. Once all information is collected, call onboard_action with confirm=false
        5. Read back the information and ask for confirmation
        6. If user confirms (says 'yes'):
        - Call onboard_action with confirm=true
        - System will enter onboarding mode
        - Inform user that onboarding mode is active and they can start demonstrating the action
        7. If user denies (says 'no'), start the process over

        Example conversation:
        User: "I want to onboard a new action"
        Assistant: "What's the name of the action you want to onboard?"
        User: "Pouring"
        Assistant: "Please provide a description of the pouring action."
        User: "Pouring soda"
        Assistant: "What objects are involved in this action?"
        User: "Red soda can and white mug"
        Assistant: [Calls onboard_action with confirm=false]
        "Please confirm the following information:
        Action: Pouring
        Description: Pouring soda
        Objects: Red soda can, white mug

        Is this information correct? Say 'yes' to confirm or 'no' to start over."
        User: "Yes"
        Assistant: [Calls onboard_action with confirm=true]
        "Great! I've created a task with ID: [task_id]. Onboarding mode is now active. You can start demonstrating the action."`;
        
        const systemPrompt = `${existingSystemPrompt}\n${systemPromptAddition}`;
        
        let onboardingMode = false;
        let simulationMode = false;
        let peerConnection = null;
        let audioStream = null;
        let dataChannel = null;
        let currentTaskId = null; 
        let currentActionName = null;
        let currentDescription = null;
        let currentObjects = null; 
        // -------------------------------------------------------------------------------------------------------------//
        // Functions
        // -------------------------------------------------------------------------------------------------------------//
        // Function Call : Handle Function Calls All the functions need to be in this call
        function handleFunctionCall(output) {
            if (output?.type === "function_call" && output?.call_id) {
                console.log('Function call found:', output);
                switch(output.name) {
                    case "get_weather":
                        handleWeatherFunction(output);
                        break;
                    case "detect_objects":
                        handleObjectDetection(output);
                        break;
                    case "record_video":
                        handelRecordVideo(output);
                        break;
                    case "check_knowledge":
                        handleCheckKnowledge(output);
                        break;
                    case "specific_knowledge_check":
                        handleSpecificKnowledgeCheck(output);
                        break;
                    case "onboard_action":
                        handleOnboardInformtation(output);
                        break;
                    case "simulate":
                        handleSimulationMode(output);
                        break;
                    case "object_centers":
                        handleObjectCenters(output);
                        break;
                    case "execution_mode":
                        handleExecutionMode(output);
                        break;
                    case "run_robot":
                        handleRunRealRobot(output);
                        break;
                    default:
                        console.log('Unknown function call:', output.name);
                }
            }
        }
        // -------------------------------------------------------------------------------------------------------------//
        // OPENAI Functions : Realtime Voice Client
        function handleTranscript(message) {
            if (message.response?.output?.[0]?.content?.[0]?.transcript) {
                let transcript = message.response.output[0].content[0].transcript;

                // Example modifications to the transcript
                transcript = transcript.replace(/\buh\b/gi, ""); // Remove "uh"
                transcript = transcript.replace(/\byou know\b/gi, ""); // Remove "you know"
                transcript = transcript.charAt(0).toUpperCase() + transcript.slice(1); // Capitalize the first letter
                transcript += "."; // Add a period at the end

                // Append the modified transcript to the transcript container
                transcriptDiv.textContent += transcript + " ";
            }
        }

        function handleInputAudioTranscriptionCompleted(message) {
            if (message.transcript) {
                // Create a span element to style the input transcription
                const inputTranscriptionElement = document.createElement("span");
                inputTranscriptionElement.className = "red-text"; // Set the class for red color
                inputTranscriptionElement.textContent = message.transcript;

                // Add the styled input transcription to the transcript container
                transcriptDiv.appendChild(inputTranscriptionElement);
                transcriptDiv.appendChild(document.createElement("br")); // Add a line break for better readability
            }
        }
        
        // -------------------------------------------------------------------------------------------------------------//
        // Weather Call : Test Function
        async function handleWeatherFunction(output) {
            try {
                const args = JSON.parse(output.arguments);
                const location = args.location;

                const response = await fetch(`${base_url}/weather/${encodeURIComponent(location)}`);
                const data = await response.json();

                // Send function output
                sendFunctionOutput(output.call_id, {
                    temperature: data.temperature,
                    unit: data.unit,
                    location: location
                });

                // Request new response
                sendResponseCreate();
            } catch (error) {
                showError('Error handling weather function: ' + error.message);
            }
        }
        // -------------------------------------------------------------------------------------------------------------//
        // Object Detection : Gemini Object Detection Function
        async function handleObjectDetection(output) {
            try {
                const args = JSON.parse(output.arguments);
                
                // TODO: Why are we using localhost , need to update to IP address
                const response = await fetch(`${base_url}/detect`);
                const data = await response.json();

                sendFunctionOutput(output.call_id, {
                    objects: data.objects,
                });

                sendResponseCreate();
            } catch (error) {
                showError('Error handling object detection: ' + error.message);
            }
        }
        // -------------------------------------------------------------------------------------------------------------//
        // ObjectCenters Mode : Gets Object Centers in Real world and sends it to Simulation as well.
        async function handleObjectCenters(output) {
            try {
                console.log('Handling object centers with output:', output);
                const args = JSON.parse(output.arguments);
                const objects = args.objects || [];
                console.log('Objects to get centers for:', objects);

                // Construct URL query parameter by converting objects array to JSON string.
                const params = new URLSearchParams();
                params.append("objects", JSON.stringify(objects));

                const response = await fetch(`${base_url}/object_centers?${params.toString()}`, {
                    method: 'GET',
                    headers: {
                        'Content-Type': 'application/json'
                    }
                });
                const data = await response.json();
                console.log('Received object centers data:', data);

                sendFunctionOutput(output.call_id, {
                    status: "success",
                    centers: data.centers
                });

                sendResponseCreate();
            } catch (error) {
                console.error('Error handling object centers:', error);
                showError('Error handling object centers: ' + error.message);
            }
        }
        // -------------------------------------------------------------------------------------------------------------//
        // Record Video : Recoed Video Function
        async function handelRecordVideo(output) {
            if (!onboardingMode) {
                console.log("Not in onboarding mode.");
                return;
            }
            try {
                const args = JSON.parse(output.arguments);
                const { objects, action, num_samples } = args;

                const response = await fetch(`${base_url}/record_video?num_recordings=${num_samples}&action_name=${action}&objects=${JSON.stringify(objects)}`, {
                    method: 'GET'
                });
                const data = await response.json();

                sendFunctionOutput(output.call_id, {
                    comment: data.comment
                });

                sendResponseCreate();
            } 
            catch (error) 
            {
                showError('Error handling recording videos: ' + error.message);
            }
        }
        // -------------------------------------------------------------------------------------------------------------//
        // Check Knowledge : Check Knowledge Function
        async function handleCheckKnowledge(output) {
            try {
                const response = await fetch(`${base_url}/check_knowledge`);
                const data = await response.json();

                sendFunctionOutput(output.call_id, {
                    actions: data.actions,
                    grasps: data.grasps
                });

                sendResponseCreate();
            } catch (error) {
                showError('Error handling check knowledge function: ' + error.message);
            }
        }
        // -------------------------------------------------------------------------------------------------------------//
        // Specific Knowledge Check :  Specific Knowledge Check Function
        async function handleSpecificKnowledgeCheck(output) {
            try {
                const args = JSON.parse(output.arguments);
                const name = args.name;

                const response = await fetch(`${base_url}/check_specific_knowledge?name=${encodeURIComponent(name)}`);
                const data = await response.json();

                sendFunctionOutput(output.call_id, {
                    name: data.name,
                    grasp: data.grasp,
                    action: data.action
                });

                sendResponseCreate();
            } catch (error) {
                showError('Error handling specific knowledge check: ' + error.message);
            }
        }
        // -------------------------------------------------------------------------------------------------------------//
        // Onboard Action : Onboard Action Function
        async function handleOnboardInformtation(output) {
            try {
                const args = JSON.parse(output.arguments);
                const { action_name, description, objects, confirm } = args;


                currentActionName = action_name;
                currentDescription = description;
                currentObjects = objects;

                const onboardResponse = await fetch(`${base_url}/onboarding_information`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        action_name,
                        description,
                        objects,
                        confirm
                    })
                });

                const responseData = await onboardResponse.json();

                if (!confirm) {
                    // First call - show confirmation message
                    sendFunctionOutput(output.call_id, {
                        status: "awaiting_confirmation",
                        details: responseData.details,
                        message: `Please confirm the following information:\nAction: ${currentActionName}\nDescription: ${currentDescription}\nObjects: ${currentObjects.join(", ")}\n\nSay 'yes' to confirm or 'no' to start over.`
                    });
                } else {
                    // Confirmation call - return result and enable onboarding mode
                    if (responseData.status === "success") {
                        onboardingMode = true;
                        currentTaskId = responseData.task_id;
                        updateStatus(`Onboarding Mode Active - Task ID: ${currentTaskId}`);
                    }

                    sendFunctionOutput(output.call_id, {
                        status: responseData.status,
                        message: responseData.message,
                        task_id: responseData.task_id,
                        onboarding_mode: onboardingMode
                    });
                }

                sendResponseCreate();
            } catch (error) {
                showError('Error handling action onboarding: ' + error.message);
                onboardingMode = false;
                currentTaskId = null;
            }
        }

        function updateStatus(message) {
            const statusDiv = document.getElementById('status');
            if (onboardingMode) {
                statusDiv.classList.add('onboarding-active');
            } else {
                statusDiv.classList.remove('onboarding-active');
            }
            statusDiv.textContent = message;
        }
        
        // -------------------------------------------------------------------------------------------------------------//
        // simulation Mode : Handle simulation Mode Function
        async function handleSimulationMode(output) {
            try {
            const args = JSON.parse(output.arguments);
            const { confirm } = args;
            
            if (!confirm) {
                sendFunctionOutput(output.call_id, {
                status: "awaiting_confirmation",
                message: "Would you like to enter simulation mode to see what I can see? Say 'yes' to confirm or 'no' to cancel."
                });
            } else {
                simulationMode = true;
                
                // TODO : Update simulation URL and open the Iframe isnstead of new tab
                // const simulationUrl = `${base_url}/simulation_feed`;
                const simulationUrl = "https://google.com";
                const newWindow = window.open(simulationUrl, '_blank');
                if (newWindow === null || typeof(newWindow) === 'undefined') {
                sendFunctionOutput(output.call_id, {
                    status: "error",
                    message: "Popup was blocked by the browser. Please allow popups for this site.",
                    simulation_mode: simulationMode
                });
                return;
                }
                
                sendFunctionOutput(output.call_id, {
                status: "success",
                message: "simulation mode activated. Opening video feed in new tab.",
                simulation_mode: simulationMode
                });
                
                updateStatus("simulation Mode Active");

                // Call loadScenario at the end of handleSimulationMode
                // await new Promise(resolve => setTimeout(resolve, 5000));
                // handleLoadScenario(output);
                
                // await new Promise(resolve => setTimeout(resolve, 5000));
                // handleTaskName(output);

                // await new Promise(resolve => setTimeout(resolve, 5000));
                // handlePlaning(output)
                
                // await new Promise(resolve => setTimeout(resolve, 5000));
                // handleRunRealRobot(output);
            }

            sendResponseCreate();
            } catch (error) {
            showError('Error handling simulation mode: ' + error.message);
            simulationMode = false;
            }
        }
        // -------------------------------------------------------------------------------------------------------------//
        // Function : Execution Mode
        async function handleExecutionMode(output) {
            try {
            console.log('Starting execution mode handler');
            const args = JSON.parse(output.arguments);
            const { confirm, objects } = args;
            console.log('Received args:', { confirm, objects });

            if (!confirm) {
                console.log('Initial execution request - checking knowledge');
                await handleCheckKnowledge(output);
                sendFunctionOutput(output.call_id, {
                status: "awaiting_task",
                message: "These are the tasks I know. Which one would you like me to perform?"
                });
                return;
            }

            if (!objects || objects.length === 0) {
                sendFunctionOutput(output.call_id, {
                status: "awaiting_objects",
                message: "What objects would you like to perform the action on?"
                });
                return;
            }

            console.log('Execution confirmed - getting object centers');
            const objectCentersArgs = { objects: objects };
            try {
                await handleObjectCenters({...output, arguments: JSON.stringify(objectCentersArgs)});
            } catch (objectCentersError) {
                console.error('Error getting object centers:', objectCentersError);
                sendFunctionOutput(output.call_id, {
                status: "object_detection_failed",
                message: "Could not detect the specified objects. Please ensure they are visible."
                });
                return;
            }

            console.log('Object centers retrieved successfully, loading simulation mode');
            handleSimulationMode(output);
            await new Promise(resolve => setTimeout(resolve, 5000));
            
            handleLoadScenario(output);
            await new Promise(resolve => setTimeout(resolve, 5000));

            console.log('Simulation mode loaded, setting task name');
            handleTaskName(output);
            await new Promise(resolve => setTimeout(resolve, 5000));

            console.log('Task name set, planning scenario');
            handlePlaning(output);
            await new Promise(resolve => setTimeout(resolve, 5000));
            
            sendResponseCreate();

            } catch (error) {
            console.error('Execution mode error:', error);
            showError('Error handling execution mode: ' + error.message);
            }
        }
        // -------------------------------------------------------------------------------------------------------------//
        // Cobot Control Function : Load Scenario
        async function handleLoadScenario(output) {
            try {
            const args = JSON.parse(output.arguments);
            const { confirm } = args;

            if (confirm === undefined) {
                sendFunctionOutput(output.call_id, {
                status: "awaiting_confirmation",
                message: "Would you like to load the scenario? Say 'yes' to confirm or 'no' to cancel."
                });
            } else {
                const response = await fetch(`${cobot_base_url}/load_scenario`, {
                method: 'PUT',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({ load_scenario: confirm })
                });
                const data = await response.json();

                sendFunctionOutput(output.call_id, {
                status: data.status,
                message: data.message
                });

                sendResponseCreate();
            }
            } catch (error) {
            showError('Error handling load scenario: ' + error.message);
            }
        }

        // Cobot Control Function : Task
        async function handleTaskName(output) {
            try {
            const task_name = currentActionName || "grasp";

            const response = await fetch(`${cobot_base_url}/task_name`, {
                method: 'PUT',
                headers: {
                'Content-Type': 'application/json'
                },
                body: JSON.stringify({ task_name })
            });
            const data = await response.json();

            sendFunctionOutput(output.call_id, {
                status: data.status,
                message: data.message
            });

            sendResponseCreate();
            } catch (error) {
            showError('Error handling task name: ' + error.message);
            }
        }

        // Cobot Control Function :  Plan
        async function handlePlaning(output) {
            try {
            const args = JSON.parse(output.arguments);
            const { confirm } = args;

            if (confirm === undefined) {
                sendFunctionOutput(output.call_id, {
                status: "awaiting_confirmation",
                message: "Would you like to plan the scenario?"
                });
            } else {
                const response = await fetch(`${cobot_base_url}/plan`, {
                method: 'PUT',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({ plan: confirm })
                });
                const data = await response.json();

                sendFunctionOutput(output.call_id, {
                status: data.status,
                message: data.message
                });

                sendResponseCreate();
            }
            } catch (error) {
            showError('Error handling load scenario: ' + error.message);
            }
        }

        // Cobot Control Function :  Execute
        async function handleRunRealRobot(output){
            // TODO : Verify cobot is running and at a safe place.
            try {
            const args = JSON.parse(output.arguments);
            const { confirm } = args;

            if (confirm === undefined) {
                sendFunctionOutput(output.call_id, {
                status: "awaiting_confirmation",
                message: "Would you like to execute the scenario?"
                });
            } else {
                const response = await fetch(`${cobot_base_url}/execute`, {
                method: 'PUT',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({ execute: confirm })
                });
                const data = await response.json();

                sendFunctionOutput(output.call_id, {
                status: data.status,
                message: data.message
                });

                sendResponseCreate();
            }
            } catch (error) {
            showError('Error handling load scenario: ' + error.message);
            }
        }

        
        // -------------------------------------------------------------------------------------------------------------//
        function handleMessage(event) {
            try {
                const message = JSON.parse(event.data);
                console.log('Full response:', message); // Log full response to console

                // Display the full response in the fullResponse container
                fullResponseDiv.textContent = JSON.stringify(message, null, 2);

                switch (message.type) {
                    case "response.done":
                        handleTranscript(message);
                        const output = message.response?.output?.[0];
                        if (output) handleFunctionCall(output);
                        break;
                    case "conversation.item.input_audio_transcription.completed":
                        handleInputAudioTranscriptionCompleted(message);
                        break;
                    default:
                        console.log('Unhandled message type:', message.type);
                }
            } catch (error) {
                showError('Error processing message: ' + error.message);
            }
        }

        // -------------------------------------------------------------------------------------------------------------//
        // WebRTC setup functions
        // -------------------------------------------------------------------------------------------------------------//
        // WebRTC setup functions
        async function setupAudio() {
            const audioEl = document.createElement("audio");
            audioEl.autoplay = true;
            peerConnection.ontrack = e => audioEl.srcObject = e.streams[0];

            audioStream = await navigator.mediaDevices.getUserMedia({ audio: true, video: true }); // Ensuring both audio and video are captured
            audioStream.getTracks().forEach(track => peerConnection.addTrack(track, audioStream)); // Add both audio and video tracks
        }

        function setupDataChannel() {
            dataChannel = peerConnection.createDataChannel("oai-events");
            dataChannel.onopen = onDataChannelOpen;
            dataChannel.addEventListener("message", handleMessage);
        }

        // -------------------------------------------------------------------------------------------------------------//
        // Function Descriptions : These Function descriptions are used by OpenAI to fo function calling based on task name and description. Be as detailed as possible
        function sendSessionUpdate() {
            const sessionUpdateEvent = {
                "type": "session.update",
                "session": {
                    "modalities": ["text", "audio"],
                    "instructions": systemPrompt,
                    "voice": "sage",
                    "input_audio_format": "pcm16",
                    "output_audio_format": "pcm16",
                    "input_audio_transcription": {
                        "model": "whisper-1"
                    },
                    "turn_detection": {
                        "type": "server_vad",
                        "threshold": 0.5,
                        "prefix_padding_ms": 300,
                        "silence_duration_ms": 500,
                        "create_response": true
                    },
                    // -------------------------------------------------------------------------------------------------------------//
                    // Tools
                    // -------------------------------------------------------------------------------------------------------------//
                    "tools": [
                        // Function: Weather
                        {
                            "type": "function",
                            "name": "get_weather",
                            "description": "Get the current weather for a location",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "location": { "type": "string" }
                                },
                                "required": ["location"]
                            }
                        },
                        // Function: Detect Objects
                        {
                            "type": "function",
                            "name": "detect_objects",
                            "description": "Detect objects using Gemini Object Detection API and returns the object names.",
                            "parameters": {
                                "type": "object",
                                "properties": {},
                                "required": []
                            }
                        },
                        // Function :  Object Centers
                        {
                            "type": "function",
                            "name": "object_centers",
                            "description": "Retrieves the real-world coordinates (as [x, y, z] triplets) of the center points of specified objects using the object detection API, and sends these coordinates along with simulation trajectory data to the simulation environment.",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "objects": {
                                        "type": "array",
                                        "items": { "type": "string" },
                                        "description": "Array of object names for which to retrieve center coordinates"
                                    }
                                },
                                "required": ["objects"]
                            }
                        },
                        // Function: Record Video
                        {
                            "type": "function",
                            "name": "record_video",
                            "description": "Records videos of specified actions with objects. Makes a GET request to record video endpoint with parameters for number of recordings, action name, and objects involved. Returns a comment about the recording status.",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "num_samples": { "type": "integer", "description": "Number of video recordings to make" },
                                    "action": { "type": "string", "description": "Name of the action being performed" },
                                    "objects": { "type": "array", "items": { "type": "string" }, "description": "Array of object names involved in the action" }
                                },
                                "required": ["num_samples", "action", "objects"]
                            }
                        },
                        // Function: Check Knowledge
                        {
                            "type": "function",
                            "name": "check_knowledge",
                            "description": "Checks its knowledge and tells the user what all it knows to grasp and what actions it can perform.",
                            "parameters": {
                                "type": "object",
                                "properties": {},
                                "required": []
                            }
                        },
                        // Function : Specific Knowledge Check
                        {
                            "type": "function",
                            "name": "specific_knowledge_check",
                            "description": "Checks specific knowledge about a named grasp or action.",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "name": { "type": "string", "description": "Name of the object or action to check knowledge about" }
                                },
                                "required": ["name"]
                            }
                        },
                        // Function : Onboard Action
                        {
                            "type": "function",
                            "name": "onboard_action",
                            "description": "Handles the onboarding process for new actions. First collects action details, then asks for confirmation, and finally creates a task if confirmed. And waits for user to say 'start recording'.",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "action_name": { 
                                        "type": "string", 
                                        "description": "Name of the action being onboarded" 
                                    },
                                    "description": { 
                                        "type": "string", 
                                        "description": "Description of the action" 
                                    },
                                    "objects": { 
                                        "type": "array", 
                                        "items": { "type": "string" }, 
                                        "description": "Array of object names involved in the action" 
                                    },
                                    "confirm": {
                                        "type": "boolean",
                                        "description": "Whether this is a confirmation request (true) or initial submission (false)"
                                    }
                                },
                                "required": ["action_name", "description", "objects", "confirm"]
                            }
                        },
                        // Functon : simulationMode
                        {
                            "type": "function",
                            "name": "simulate",
                            "description": "Enables simulation mode to show the robot's simulation in a new browser tab. Requires user confirmation.",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "confirm": {
                                        "type": "boolean",
                                        "description": "Whether this is a confirmation request (true) or initial request (false)"
                                    }
                                },
                                "required": ["confirm"]
                            }
                        },
                        // Function : loadScenario
                        {
                            "type": "function",
                            "name": "load_scenario",
                            "description": "Confirm if user wants to load the scene.",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "confirm": { "type": "boolean", "description": "This is a confirmation request to user , to confirm if they want to load the scene in Simulation or not." }
                                },
                                "required": ["confirm"]
                            }
                        },
                        // Function : Task Name
                        {
                            "type": "function",
                            "name": "task_name",
                            "description": "Set a Specific task name.",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "task_name": { "type": "string", "description": "Name of the task to set for the cobot" }
                                },
                                "required": ["task_name"]
                            }
                        },
                        // Function: ExecutionMode
                        {
                            "type": "function",
                            "name": "execution_mode",
                            "description": "Enables execution mode where the robot performs the selected task. Shows available actions, detects objects, and requires user confirmation and user to select the objects and task.",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "confirm": {
                                        "type": "boolean",
                                        "description": "Whether this is a confirmation request (true) or initial request (false)"
                                    },
                                    "objects": {
                                        "type": "array",
                                        "items": { "type": "string" },
                                        "description": "Array of objects to use in the task"
                                    }
                                },
                                "required": ["confirm"]
                            }
                        }

                    ],
                    "tool_choice": "auto",
                    "temperature": 0.8,
                    "max_response_output_tokens": "inf"
                }
            };
            sendMessage(sessionUpdateEvent);
        }

        function sendFunctionOutput(callId, data) {
            const responseMessage = {
                "type": "conversation.item.create",
                "item": {
                    "type": "function_call_output",
                    "call_id": callId,
                    "output": JSON.stringify(data)
                }
            };
            sendMessage(responseMessage);
        }

        function sendResponseCreate() {
            sendMessage({ "type": "response.create" });
        }

        function sendMessage(message) {
            if (dataChannel?.readyState === "open") {
                dataChannel.send(JSON.stringify(message));
                console.log('Sent message:', message);
            }
        }

        function onDataChannelOpen() {
            sendSessionUpdate();
        }

        // -------------------------------------------------------------------------------------------------------------//
        // Main control functions
        // -------------------------------------------------------------------------------------------------------------//
        async function init() {
            startButton.disabled = true;
            try {
                updateStatus('Initializing...');
                const tokenResponse = await fetch(`${base_url}/session`);
                const data = await tokenResponse.json();
                const EPHEMERAL_KEY = data.client_secret.value;

                peerConnection = new RTCPeerConnection();
                await setupAudio(); // Ensures audio and video tracks are added to peerConnection
                setupDataChannel();

                const offer = await peerConnection.createOffer();
                await peerConnection.setLocalDescription(offer);

                console.log("SDP Offer:", peerConnection.localDescription.sdp); // Log SDP for debugging

                const baseUrl = "https://api.openai.com/v1/realtime";
                const model = "gpt-4o-realtime-preview-2024-12-17";
                const sdpResponse = await fetch(`${baseUrl}?model=${model}`, {
                    method: "POST",
                    body: offer.sdp,
                    headers: {
                        Authorization: `Bearer ${EPHEMERAL_KEY}`,
                        "Content-Type": "application/sdp"
                    },
                });

                const answer = {
                    type: "answer",
                    sdp: await sdpResponse.text(),
                };
                await peerConnection.setRemoteDescription(answer);

                updateStatus('Connected');
                stopButton.disabled = false;
                hideError();
            } catch (error) {
                startButton.disabled = false;
                stopButton.disabled = true;
                showError('Error: ' + error.message);
                console.error('Initialization error:', error);
                updateStatus('Failed to connect');
            }
        }

        function stopRecording() {
            if (peerConnection) {
                peerConnection.close();
                peerConnection = null;
            }
            if (audioStream) {
                audioStream.getTracks().forEach(track => track.stop());
                audioStream = null;
            }
            if (dataChannel) {
                dataChannel.close();
                dataChannel = null;
            }
            startButton.disabled = false;
            stopButton.disabled = true;
            updateStatus('Ready to start');
        }

        // -------------------------------------------------------------------------------------------------------------//
        // UI helper functions
        function updateStatus(message) {
            statusDiv.textContent = message;
        }

        function showError(message) {
            errorDiv.style.display = 'block';
            errorDiv.textContent = message;
        }

        function hideError() {
            errorDiv.style.display = 'none';
        }

        // -------------------------------------------------------------------------------------------------------------//
        // Event listeners
        startButton.addEventListener('click', init);
        stopButton.addEventListener('click', stopRecording);
        document.addEventListener('DOMContentLoaded', () => updateStatus('Ready to start'));
    </script>
</body>
</html>