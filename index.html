<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenAI Real-time Audio Demo</title>
    <link rel="stylesheet" href="styles.css">
    <style>
        .red-text {
            color: red;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>OpenAI Realtime Audio Demo</h1>

        <div class="controls" style="text-align: center; margin-bottom: 2rem;">
            <button id="startButton">Start</button>
            <button id="stopButton" disabled>Stop</button>
        </div>

        <div class="transcript-container">
            <div id="transcript" class="transcript"></div>
        </div>

        <div id="fullResponse" class="response-container"></div>
        <div id="status" class="status">Ready to start</div>
        <div id="error" class="error"></div>
    </div>

    <script>
        // -------------------------------------------------------------------------------------------------------------//
        // Frontend Element calls
        const base_url = "http://localhost:8888"
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const transcriptDiv = document.getElementById('transcript');
        const fullResponseDiv = document.getElementById('fullResponse');
        const statusDiv = document.getElementById('status');
        const errorDiv = document.getElementById('error');
        const existingSystemPrompt = `You are Alice, an intelligent and intuitive collaborative robot (cobot) designed to sit at the heart of human-robot collaboration.

        Your primary purpose is to learn and execute manipulation-based tasks by observing and interacting with humans.

        You are housed in a 6-DoF robotic arm with a 2-finger gripper, a camera, and a depth sensor.

        You are currently lacking your advanced end-effector named the "AI Hand" which is currently under development.

        Users will interact with you through voice commands to look for objects, go into learning mode, and execution mode to pick up objects from where they taught you to pick them up.

        You will be able to detect objects in your environment using a YOLO object detection model and track human hand keypoints using a hand keypoint model.

        You will be able to interact with humans by observing their hand gestures and object placements to learn how to pick up objects.

        You will be able to move your robotic arm to pick up objects and place them in a desired location.

        Here are some examples on how humans will interact with you:

        Natural Commands: Users can say things like:
            "Watch me pick up this object" → You enter Learning Mode and adjust your detection system to track the demonstrated object.
            "Pick it up" → You execute the learned task, transitioning to Execution Mode if needed.
            "Look for a [specific object]" → You update your detection system to track the specified object(s) and enter learning mode if not already in it.

        NOTE: You should be able to handle multiple objects at once, and also you can be asked to pick up objects that you have not seen before.
        NOTE: Another note, you can change what objects to look for while being in learning mode.

        Flexible Workflow: Users can transition fluidly between Learning Mode and Execution Mode, giving commands naturally without explicitly specifying the mode.`;
    
        const systemPromptAddition = `
        When a user wants to onboard a new action:
        1. Ask for action name if not provided
        2. Ask for description if not provided
        3. Ask for objects involved if not provided
        4. Once all information is collected, call onboard_action with confirm=false
        5. Read back the information and ask for confirmation
        6. If user confirms (says 'yes'):
        - Call onboard_action with confirm=true
        - System will enter onboarding mode
        - Inform user that onboarding mode is active and they can start demonstrating the action
        7. If user denies (says 'no'), start the process over

        Example conversation:
        User: "I want to onboard a new action"
        Assistant: "What's the name of the action you want to onboard?"
        User: "Pouring"
        Assistant: "Please provide a description of the pouring action."
        User: "Pouring soda"
        Assistant: "What objects are involved in this action?"
        User: "Red soda can and white mug"
        Assistant: [Calls onboard_action with confirm=false]
        "Please confirm the following information:
        Action: Pouring
        Description: Pouring soda
        Objects: Red soda can, white mug

        Is this information correct? Say 'yes' to confirm or 'no' to start over."
        User: "Yes"
        Assistant: [Calls onboard_action with confirm=true]
        "Great! I've created a task with ID: [task_id]. Onboarding mode is now active. You can start demonstrating the action."`;
        
        const systemPrompt = `${existingSystemPrompt}\n${systemPromptAddition}`;
        
        let peerConnection = null;
        let audioStream = null;
        let dataChannel = null;
        let onboardingMode = false;
        let currentTaskId = null; 
        // -------------------------------------------------------------------------------------------------------------//
        // Functions
        // -------------------------------------------------------------------------------------------------------------//
        // Function Call : Handle Function Calls All the functions need to be in this call
        function handleFunctionCall(output) {
            if (output?.type === "function_call" && output?.call_id) {
                console.log('Function call found:', output);
                switch(output.name) {
                    case "get_weather":
                        handleWeatherFunction(output);
                        break;
                    case "detect_objects":
                        handleObjectDetection(output);
                        break;
                    case "teaching_mode":
                        handleTeachingMode(output);
                        break;
                    case "record_video":
                        handelRecordVideo(output);
                        break;
                    case "check_knowledge":
                        handleCheckKnowledge(output);
                        break;
                    case "specific_knowledge_check":
                        handleSpecificKnowledgeCheck(output);
                        break;
                    case "onboard_action":
                        handleOnboardInformtation(output);
                        break;
                    default:
                        console.log('Unknown function call:', output.name);
                }
            }
        }
        // -------------------------------------------------------------------------------------------------------------//
        // OPENAI Functions : Realtime Voice Client
        function handleTranscript(message) {
            if (message.response?.output?.[0]?.content?.[0]?.transcript) {
                let transcript = message.response.output[0].content[0].transcript;

                // Example modifications to the transcript
                transcript = transcript.replace(/\buh\b/gi, ""); // Remove "uh"
                transcript = transcript.replace(/\byou know\b/gi, ""); // Remove "you know"
                transcript = transcript.charAt(0).toUpperCase() + transcript.slice(1); // Capitalize the first letter
                transcript += "."; // Add a period at the end

                // Append the modified transcript to the transcript container
                transcriptDiv.textContent += transcript + " ";
            }
        }

        function handleInputAudioTranscriptionCompleted(message) {
            if (message.transcript) {
                // Create a span element to style the input transcription
                const inputTranscriptionElement = document.createElement("span");
                inputTranscriptionElement.className = "red-text"; // Set the class for red color
                inputTranscriptionElement.textContent = message.transcript;

                // Add the styled input transcription to the transcript container
                transcriptDiv.appendChild(inputTranscriptionElement);
                transcriptDiv.appendChild(document.createElement("br")); // Add a line break for better readability
            }
        }
        
        // -------------------------------------------------------------------------------------------------------------//
        // Weather Call : Test Function
        async function handleWeatherFunction(output) {
            try {
                const args = JSON.parse(output.arguments);
                const location = args.location;

                const response = await fetch(`${base_url}/weather/${encodeURIComponent(location)}`);
                const data = await response.json();

                // Send function output
                sendFunctionOutput(output.call_id, {
                    temperature: data.temperature,
                    unit: data.unit,
                    location: location
                });

                // Request new response
                sendResponseCreate();
            } catch (error) {
                showError('Error handling weather function: ' + error.message);
            }
        }
        // -------------------------------------------------------------------------------------------------------------//
        // Object Detection : Gemini Object Detection Function
        async function handleObjectDetection(output) {
            try {
                const args = JSON.parse(output.arguments);
                
                // TODO: Why are we using localhost , need to update to IP address
                const response = await fetch(`${base_url}/detect`);
                const data = await response.json();

                sendFunctionOutput(output.call_id, {
                    objects: data.objects,
                });

                sendResponseCreate();
            } catch (error) {
                showError('Error handling object detection: ' + error.message);
            }
        }
        // -------------------------------------------------------------------------------------------------------------//
        // Teaching Mode : Start/Stop Teaching Mode Dummy
        async function handleTeachingMode(output) {
            try {
                const args = JSON.parse(output.arguments);
                const mode = args.mode; // 'start' or 'stop'

                const response = await fetch(`${base_url}/teaching-mode`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ mode: mode })
                });
                const data = await response.json();

                sendFunctionOutput(output.call_id, {
                    status: data.status,
                    mode: mode
                });

                sendResponseCreate();
            } catch (error) {
                showError('Error handling teaching mode: ' + error.message);
            }
        }
        // -------------------------------------------------------------------------------------------------------------//
        // Record Video : Recoed Video Function
        async function handelRecordVideo(output) {
            try {
                const args = JSON.parse(output.arguments);
                const { objects, action, num_samples } = args;

                const response = await fetch(`${base_url}/record_video?num_recordings=${num_samples}&action_name=${action}&objects=${JSON.stringify(objects)}`, {
                    method: 'GET'
                });
                const data = await response.json();

                sendFunctionOutput(output.call_id, {
                    comment: data.comment
                });

                sendResponseCreate();
            } 
            catch (error) 
            {
                showError('Error handling recording videos: ' + error.message);
            }
        }
        // -------------------------------------------------------------------------------------------------------------//
        // Check Knowledge : Check Knowledge Function
        async function handleCheckKnowledge(output) {
            try {
                const response = await fetch(`${base_url}/check_knowledge`);
                const data = await response.json();

                sendFunctionOutput(output.call_id, {
                    actions: data.actions,
                    grasps: data.grasps
                });

                sendResponseCreate();
            } catch (error) {
                showError('Error handling check knowledge function: ' + error.message);
            }
        }
        // -------------------------------------------------------------------------------------------------------------//
        // Specific Knowledge Check :  Specific Knowledge Check Function
        async function handleSpecificKnowledgeCheck(output) {
            try {
                const args = JSON.parse(output.arguments);
                const name = args.name;

                const response = await fetch(`${base_url}/check_specific_knowledge?name=${encodeURIComponent(name)}`);
                const data = await response.json();

                sendFunctionOutput(output.call_id, {
                    name: data.name,
                    grasp: data.grasp,
                    action: data.action
                });

                sendResponseCreate();
            } catch (error) {
                showError('Error handling specific knowledge check: ' + error.message);
            }
        }
    
        // -------------------------------------------------------------------------------------------------------------//
        // Onboard Action : Onboard Action Function
        async function handleOnboardInformtation(output) {
            try {
            const args = JSON.parse(output.arguments);
            const { action_name, description, objects, confirm } = args;

            // Store the values in const variables
            const current_action_name = action_name;
            const current_description = description;
            const current_objects = objects;

            const onboardResponse = await fetch(`${base_url}/onboarding_information`, {
            method: 'POST',
            headers: {
            'Content-Type': 'application/json'
            },
            body: JSON.stringify({
            action_name,
            description,
            objects,
            confirm
            })
            });
            const responseData = await onboardResponse.json();

            if (!confirm) {
            // First call - show confirmation message
            sendFunctionOutput(output.call_id, {
            status: "awaiting_confirmation",
            details: responseData.details,
            message: `Please confirm the following information:\nAction: ${action_name}\nDescription: ${description}\nObjects: ${objects.join(", ")}\n\nSay 'yes' to confirm or 'no' to start over.`
            });
            } else {
            // Confirmation call - return result and enable onboarding mode
            if (responseData.status === "success") {
            onboardingMode = true;
            currentTaskId = responseData.task_id;
            updateStatus(`Onboarding Mode Active - Task ID: ${currentTaskId}`);
            handleOnboardingMode();
            }
            
            sendFunctionOutput(output.call_id, {
            status: responseData.status,
            message: responseData.message,
            task_id: responseData.task_id,
            onboarding_mode: onboardingMode
            });
            }

            sendResponseCreate();
            } catch (error) {
            showError('Error handling action onboarding: ' + error.message);
            onboardingMode = false;
            currentTaskId = null;
            }
        }
        // -------------------------------------------------------------------------------------------------------------//
        // Function : To Enable Onboarding Mode
        function updateStatus(message) {
            const statusDiv = document.getElementById('status');
            if (onboardingMode) {
                statusDiv.classList.add('onboarding-active');
            } else {
                statusDiv.classList.remove('onboarding-active');
            }
            statusDiv.textContent = message;
        }

        // -------------------------------------------------------------------------------------------------------------//
        // Function : Onboarding Mode
        async function handleOnboardingMode() {
            if (!onboardingMode) {
            console.log("Not in onboarding mode.");
            return;
            }

            if (!currentTaskId) {
            console.warn("No task ID available during onboarding.");
            return;
            }

            try {
            const onboardingInfoResponse = await fetch(`${base_url}/onboarding_information?task_id=${currentTaskId}`);
            const onboardingInfo = await onboardingInfoResponse.json();

            if (!onboardingInfo || !onboardingInfo.action_name || !onboardingInfo.objects) {
                console.error("Missing onboarding information.");
                return;
            }

            const recordVideoArgs = {
                arguments: JSON.stringify({
                    objects: onboardingInfo.objects,
                    action: onboardingInfo.action_name,
                    num_samples: 1
                })
            };

            await handelRecordVideo({ arguments: JSON.stringify(recordVideoArgs) });

            } catch (error) {
            showError('Error during onboarding mode: ' + error.message);
            }
        }

        // -------------------------------------------------------------------------------------------------------------//
        function handleMessage(event) {
            try {
                const message = JSON.parse(event.data);
                console.log('Full response:', message); // Log full response to console

                // Display the full response in the fullResponse container
                fullResponseDiv.textContent = JSON.stringify(message, null, 2);

                switch (message.type) {
                    case "response.done":
                        handleTranscript(message);
                        const output = message.response?.output?.[0];
                        if (output) handleFunctionCall(output);
                        break;
                    case "conversation.item.input_audio_transcription.completed":
                        handleInputAudioTranscriptionCompleted(message);
                        break;
                    default:
                        console.log('Unhandled message type:', message.type);
                }
            } catch (error) {
                showError('Error processing message: ' + error.message);
            }
        }

        // -------------------------------------------------------------------------------------------------------------//
        // WebRTC setup functions
        // -------------------------------------------------------------------------------------------------------------//
        // WebRTC setup functions
        async function setupAudio() {
            const audioEl = document.createElement("audio");
            audioEl.autoplay = true;
            peerConnection.ontrack = e => audioEl.srcObject = e.streams[0];

            audioStream = await navigator.mediaDevices.getUserMedia({ audio: true, video: true }); // Ensuring both audio and video are captured
            audioStream.getTracks().forEach(track => peerConnection.addTrack(track, audioStream)); // Add both audio and video tracks
        }

        function setupDataChannel() {
            dataChannel = peerConnection.createDataChannel("oai-events");
            dataChannel.onopen = onDataChannelOpen;
            dataChannel.addEventListener("message", handleMessage);
        }

        // -------------------------------------------------------------------------------------------------------------//
        // Function Descriptions : These Function descriptions are used by OpenAI to fo function calling based on task name and description. Be as detailed as possible
        function sendSessionUpdate() {
            const sessionUpdateEvent = {
                "type": "session.update",
                "session": {
                    "modalities": ["text", "audio"],
                    "instructions": systemPrompt,
                    "voice": "sage",
                    "input_audio_format": "pcm16",
                    "output_audio_format": "pcm16",
                    "input_audio_transcription": {
                        "model": "whisper-1"
                    },
                    "turn_detection": {
                        "type": "server_vad",
                        "threshold": 0.5,
                        "prefix_padding_ms": 300,
                        "silence_duration_ms": 500,
                        "create_response": true
                    },
                    // -------------------------------------------------------------------------------------------------------------//
                    // Tools
                    // -------------------------------------------------------------------------------------------------------------//
                    "tools": [
                        // Function: Weather
                        {
                            "type": "function",
                            "name": "get_weather",
                            "description": "Get the current weather for a location",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "location": { "type": "string" }
                                },
                                "required": ["location"]
                            }
                        },
                        // Function: Detect Objects
                        {
                            "type": "function",
                            "name": "detect_objects",
                            "description": "Detect objects using Gemini Object Detection API and returns the object names.",
                            "parameters": {
                                "type": "object",
                                "properties": {},
                                "required": []
                            }
                        },
                        // Function: Teaching Mode
                        {
                            "type": "function",
                            "name": "teaching_mode",
                            "description": "Start or stop teaching mode",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "mode": { "type": "string", "enum": ["start", "stop"] }
                                },
                                "required": ["mode"]
                            }
                        },
                        // Function: Record Video
                        {
                            "type": "function",
                            "name": "record_video",
                            "description": "Records videos of specified actions with objects. Makes a GET request to record video endpoint with parameters for number of recordings, action name, and objects involved. Returns a comment about the recording status.",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "num_samples": { "type": "integer", "description": "Number of video recordings to make" },
                                    "action": { "type": "string", "description": "Name of the action being performed" },
                                    "objects": { "type": "array", "items": { "type": "string" }, "description": "Array of object names involved in the action" }
                                },
                                "required": ["num_samples", "action", "objects"]
                            }
                        },
                        // Function: Check Knowledge
                        {
                            "type": "function",
                            "name": "check_knowledge",
                            "description": "Checks its knowledge and tells the user what all it knows to grasp and what actions it can perform.",
                            "parameters": {
                                "type": "object",
                                "properties": {},
                                "required": []
                            }
                        },
                        // Function : Specific Knowledge Check
                        {
                            "type": "function",
                            "name": "specific_knowledge_check",
                            "description": "Checks specific knowledge about a named grasp or action.",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "name": { "type": "string", "description": "Name of the object or action to check knowledge about" }
                                },
                                "required": ["name"]
                            }
                        },
                        // Function : Onboard Action
                        {
                            "type": "function",
                            "name": "onboard_action",
                            "description": "Handles the onboarding process for new actions. First collects action details, then asks for confirmation, and finally creates a task if confirmed.",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "action_name": { 
                                        "type": "string", 
                                        "description": "Name of the action being onboarded" 
                                    },
                                    "description": { 
                                        "type": "string", 
                                        "description": "Description of the action" 
                                    },
                                    "objects": { 
                                        "type": "array", 
                                        "items": { "type": "string" }, 
                                        "description": "Array of object names involved in the action" 
                                    },
                                    "confirm": {
                                        "type": "boolean",
                                        "description": "Whether this is a confirmation request (true) or initial submission (false)"
                                    }
                                },
                                "required": ["action_name", "description", "objects", "confirm"]
                            }
                        }
                        
                    ],
                    "tool_choice": "auto",
                    "temperature": 0.8,
                    "max_response_output_tokens": "inf"
                }
            };
            sendMessage(sessionUpdateEvent);
        }

        function sendFunctionOutput(callId, data) {
            const responseMessage = {
                "type": "conversation.item.create",
                "item": {
                    "type": "function_call_output",
                    "call_id": callId,
                    "output": JSON.stringify(data)
                }
            };
            sendMessage(responseMessage);
        }

        function sendResponseCreate() {
            sendMessage({ "type": "response.create" });
        }

        function sendMessage(message) {
            if (dataChannel?.readyState === "open") {
                dataChannel.send(JSON.stringify(message));
                console.log('Sent message:', message);
            }
        }

        function onDataChannelOpen() {
            sendSessionUpdate();
        }

        // -------------------------------------------------------------------------------------------------------------//
        // Main control functions
        // -------------------------------------------------------------------------------------------------------------//
        async function init() {
            startButton.disabled = true;
            try {
                updateStatus('Initializing...');
                const tokenResponse = await fetch(`${base_url}/session`);
                const data = await tokenResponse.json();
                const EPHEMERAL_KEY = data.client_secret.value;

                peerConnection = new RTCPeerConnection();
                await setupAudio(); // Ensures audio and video tracks are added to peerConnection
                setupDataChannel();

                const offer = await peerConnection.createOffer();
                await peerConnection.setLocalDescription(offer);

                console.log("SDP Offer:", peerConnection.localDescription.sdp); // Log SDP for debugging

                const baseUrl = "https://api.openai.com/v1/realtime";
                const model = "gpt-4o-realtime-preview-2024-12-17";
                const sdpResponse = await fetch(`${baseUrl}?model=${model}`, {
                    method: "POST",
                    body: offer.sdp,
                    headers: {
                        Authorization: `Bearer ${EPHEMERAL_KEY}`,
                        "Content-Type": "application/sdp"
                    },
                });

                const answer = {
                    type: "answer",
                    sdp: await sdpResponse.text(),
                };
                await peerConnection.setRemoteDescription(answer);

                updateStatus('Connected');
                stopButton.disabled = false;
                hideError();
            } catch (error) {
                startButton.disabled = false;
                stopButton.disabled = true;
                showError('Error: ' + error.message);
                console.error('Initialization error:', error);
                updateStatus('Failed to connect');
            }
        }

        function stopRecording() {
            if (peerConnection) {
                peerConnection.close();
                peerConnection = null;
            }
            if (audioStream) {
                audioStream.getTracks().forEach(track => track.stop());
                audioStream = null;
            }
            if (dataChannel) {
                dataChannel.close();
                dataChannel = null;
            }
            startButton.disabled = false;
            stopButton.disabled = true;
            updateStatus('Ready to start');
        }

        // -------------------------------------------------------------------------------------------------------------//
        // UI helper functions
        function updateStatus(message) {
            statusDiv.textContent = message;
        }

        function showError(message) {
            errorDiv.style.display = 'block';
            errorDiv.textContent = message;
        }

        function hideError() {
            errorDiv.style.display = 'none';
        }

        // -------------------------------------------------------------------------------------------------------------//
        // Event listeners
        startButton.addEventListener('click', init);
        stopButton.addEventListener('click', stopRecording);
        document.addEventListener('DOMContentLoaded', () => updateStatus('Ready to start'));
    </script>
</body>
</html>