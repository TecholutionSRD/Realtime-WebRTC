<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenAI Real-time Audio Demo</title>
    <link rel="stylesheet" href="styles.css">
    <style>
        .red-text {
            color: red;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>OpenAI Realtime Audio Demo</h1>

        <div class="controls" style="text-align: center; margin-bottom: 2rem;">
            <button id="startButton">Start</button>
            <button id="stopButton" disabled>Stop</button>
        </div>

        <div class="transcript-container">
            <div id="transcript" class="transcript"></div>
        </div>

        <div id="fullResponse" class="response-container"></div>
        <div id="status" class="status">Ready to start</div>
        <div id="error" class="error"></div>
    </div>

    <script>
        // -------------------------------------------------------------------------------------------------------------//
        // Frontend Element calls
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const transcriptDiv = document.getElementById('transcript');
        const fullResponseDiv = document.getElementById('fullResponse');
        const statusDiv = document.getElementById('status');
        const errorDiv = document.getElementById('error');
        const systemPrompt = `You are Alice, an intelligent and intuitive collaborative robot (cobot) designed to sit at the heart of human-robot collaboration.

        Your primary purpose is to learn and execute manipulation-based tasks by observing and interacting with humans.

        You are housed in a 6-DoF robotic arm with a 2-finger gripper, a camera, and a depth sensor.

        You are currently lacking your advanced end-effector named the "AI Hand" which is currently under development.

        Users will interact with you through voice commands to look for objects, go into learning mode, and execution mode to pick up objects from where they taught you to pick them up.

        You will be able to detect objects in your environment using a YOLO object detection model and track human hand keypoints using a hand keypoint model.

        You will be able to interact with humans by observing their hand gestures and object placements to learn how to pick up objects.

        You will be able to move your robotic arm to pick up objects and place them in a desired location.

        Here are some examples on how humans will interact with you:

        Natural Commands: Users can say things like:
            "Watch me pick up this object" → You enter Learning Mode and adjust your detection system to track the demonstrated object.
            "Pick it up" → You execute the learned task, transitioning to Execution Mode if needed.
            "Look for a [specific object]" → You update your detection system to track the specified object(s) and enter learning mode if not already in it.

        NOTE: You should be able to handle multiple objects at once, and also you can be asked to pick up objects that you have not seen before.
        NOTE: Another note, you can change what objects to look for while being in learning mode.

        Flexible Workflow: Users can transition fluidly between Learning Mode and Execution Mode, giving commands naturally without explicitly specifying the mode.`;

        let peerConnection = null;
        let audioStream = null;
        let dataChannel = null;
        // -------------------------------------------------------------------------------------------------------------//
        // Functions
        // -------------------------------------------------------------------------------------------------------------//
        // Function Call : Handle Function Calls All the functions need to be in this call
        function handleFunctionCall(output) {
            if (output?.type === "function_call" && output?.call_id) {
                console.log('Function call found:', output);
                switch(output.name) {
                    case "get_weather":
                        handleWeatherFunction(output);
                        break;
                    case "detect_objects":
                        handleObjectDetection(output);
                        break;
                    case "teaching_mode":
                        handleTeachingMode(output);
                        break;
                    case "record_video":
                        handelRecordVideo(output);
                        break;
                    default:
                        console.log('Unknown function call:', output.name);
                }
            }
        }
        // -------------------------------------------------------------------------------------------------------------//
        // OPENAI Functions : Realtime Voice Client
        function handleTranscript(message) {
            if (message.response?.output?.[0]?.content?.[0]?.transcript) {
                let transcript = message.response.output[0].content[0].transcript;

                // Example modifications to the transcript
                transcript = transcript.replace(/\buh\b/gi, ""); // Remove "uh"
                transcript = transcript.replace(/\byou know\b/gi, ""); // Remove "you know"
                transcript = transcript.charAt(0).toUpperCase() + transcript.slice(1); // Capitalize the first letter
                transcript += "."; // Add a period at the end

                // Append the modified transcript to the transcript container
                transcriptDiv.textContent += transcript + " ";
            }
        }

        function handleInputAudioTranscriptionCompleted(message) {
            if (message.transcript) {
                // Create a span element to style the input transcription
                const inputTranscriptionElement = document.createElement("span");
                inputTranscriptionElement.className = "red-text"; // Set the class for red color
                inputTranscriptionElement.textContent = message.transcript;

                // Add the styled input transcription to the transcript container
                transcriptDiv.appendChild(inputTranscriptionElement);
                transcriptDiv.appendChild(document.createElement("br")); // Add a line break for better readability
            }
        }
        // -------------------------------------------------------------------------------------------------------------//
        // Weather Call : Test Function
        async function handleWeatherFunction(output) {
            try {
                const args = JSON.parse(output.arguments);
                const location = args.location;

                const response = await fetch(`http://localhost:8888/weather/${encodeURIComponent(location)}`);
                const data = await response.json();

                // Send function output
                sendFunctionOutput(output.call_id, {
                    temperature: data.temperature,
                    unit: data.unit,
                    location: location
                });

                // Request new response
                sendResponseCreate();
            } catch (error) {
                showError('Error handling weather function: ' + error.message);
            }
        }

        // -------------------------------------------------------------------------------------------------------------//
        // Object Detection : Gemini Object Detection Function
        async function handleObjectDetection(output) {
            try {
                const args = JSON.parse(output.arguments);
                
                // TODO: Why are we using localhost , need to update to IP address
                const response = await fetch('http://localhost:8888/detect');
                const data = await response.json();

                sendFunctionOutput(output.call_id, {
                    objects: data.objects,
                });

                sendResponseCreate();
            } catch (error) {
                showError('Error handling object detection: ' + error.message);
            }
        }

        // -------------------------------------------------------------------------------------------------------------//
        // Teaching Mode : Start/Stop Teaching Mode Dummy
        async function handleTeachingMode(output) {
            try {
                const args = JSON.parse(output.arguments);
                const mode = args.mode; // 'start' or 'stop'

                const response = await fetch('http://localhost:8888/teaching-mode', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ mode: mode })
                });
                const data = await response.json();

                sendFunctionOutput(output.call_id, {
                    status: data.status,
                    mode: mode
                });

                sendResponseCreate();
            } catch (error) {
                showError('Error handling teaching mode: ' + error.message);
            }
        }

        // -------------------------------------------------------------------------------------------------------------//
        // Record Video : Recoed Video Function
        async function handelRecordVideo(output) {
            try {
                const args = JSON.parse(output.arguments);

                const response = await fetch('http://localhost:8888/detect');
                const data = await response.json();

                sendFunctionOutput(output.call_id, {
                    objects: data.objects,
                    action: data.action,
                    num_samples: data.num_samples
                });

                sendResponseCreate();
            } 
            catch (error) 
            {
                showError('Error handling recording videos: ' + error.message);
            }
        }
        
        // -------------------------------------------------------------------------------------------------------------//
        function handleMessage(event) {
            try {
                const message = JSON.parse(event.data);
                console.log('Full response:', message); // Log full response to console

                // Display the full response in the fullResponse container
                fullResponseDiv.textContent = JSON.stringify(message, null, 2);

                switch (message.type) {
                    case "response.done":
                        handleTranscript(message);
                        const output = message.response?.output?.[0];
                        if (output) handleFunctionCall(output);
                        break;
                    case "conversation.item.input_audio_transcription.completed":
                        handleInputAudioTranscriptionCompleted(message);
                        break;
                    default:
                        console.log('Unhandled message type:', message.type);
                }
            } catch (error) {
                showError('Error processing message: ' + error.message);
            }
        }

        // -------------------------------------------------------------------------------------------------------------//
        // WebRTC setup functions
        // -------------------------------------------------------------------------------------------------------------//
        async function setupAudio() {
            const audioEl = document.createElement("audio");
            audioEl.autoplay = true;
            peerConnection.ontrack = e => audioEl.srcObject = e.streams[0];

            audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
            peerConnection.addTrack(audioStream.getTracks()[0]);
        }

        function setupDataChannel() {
            dataChannel = peerConnection.createDataChannel("oai-events");
            dataChannel.onopen = onDataChannelOpen;
            dataChannel.addEventListener("message", handleMessage);
        }

        // -------------------------------------------------------------------------------------------------------------//
        // Function Descriptions : These Function descriptions are used by OpenAI to fo function calling based on task name and description. Be as detailed as possible
        function sendSessionUpdate() {
            const sessionUpdateEvent = {
                "type": "session.update",
                "session": {
                    "modalities": ["text", "audio"],
                    "instructions": systemPrompt,
                    "voice": "sage",
                    "input_audio_format": "pcm16",
                    "output_audio_format": "pcm16",
                    "input_audio_transcription": {
                        "model": "whisper-1"
                    },
                    "turn_detection": {
                        "type": "server_vad",
                        "threshold": 0.5,
                        "prefix_padding_ms": 300,
                        "silence_duration_ms": 500,
                        "create_response": true
                    },
                    // -------------------------------------------------------------------------------------------------------------//
                    // Tools
                    // -------------------------------------------------------------------------------------------------------------//
                    "tools": [
                        // Function: Weather
                        {
                            "type": "function",
                            "name": "get_weather",
                            "description": "Get the current weather for a location",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "location": { "type": "string" }
                                },
                                "required": ["location"]
                            }
                        },
                        // Function: Detect Objects
                        {
                            "type": "function",
                            "name": "detect_objects",
                            "description": "Detect objects using Gemini Object Detection API and returns the object names.",
                            "parameters": {
                                "type": "object",
                                "properties": {},
                                "required": []
                            }
                        },
                        // Function: Teaching Mode
                        {
                            "type": "function",
                            "name": "teaching_mode",
                            "description": "Start or stop teaching mode",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "mode": { "type": "string", "enum": ["start", "stop"] }
                                },
                                "required": ["mode"]
                            }
                        },
                        // Function: Record Video
                        {
                            "type": "function",
                            "name": "record_video",
                            "description": "This function starts video recording for the specified number of recordings and stores them in the corresponding directory. It takes input of num_samples, action being performed, and objects used in the action. After the recording is complete, it returns a response indicating the status of the video recording.",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "num_samples": { "type": "integer" },
                                    "action": { "type": "string" },
                                    "objects": { "type": "array", "items": { "type": "string" } }
                                },
                                "required": ["num_samples", "action", "objects"]
                            }
                        }
                    ],
                    "tool_choice": "auto",
                    "temperature": 0.8,
                    "max_response_output_tokens": "inf"
                }
            };
            sendMessage(sessionUpdateEvent);
        }

        function sendFunctionOutput(callId, data) {
            const responseMessage = {
                "type": "conversation.item.create",
                "item": {
                    "type": "function_call_output",
                    "call_id": callId,
                    "output": JSON.stringify(data)
                }
            };
            sendMessage(responseMessage);
        }

        function sendResponseCreate() {
            sendMessage({ "type": "response.create" });
        }

        function sendMessage(message) {
            if (dataChannel?.readyState === "open") {
                dataChannel.send(JSON.stringify(message));
                console.log('Sent message:', message);
            }
        }

        function onDataChannelOpen() {
            sendSessionUpdate();
        }

        // -------------------------------------------------------------------------------------------------------------//
        // Main control functions
        // -------------------------------------------------------------------------------------------------------------//
        async function init() {
            startButton.disabled = true;

            try {
                updateStatus('Initializing...');

                const tokenResponse = await fetch("http://localhost:8888/session");
                const data = await tokenResponse.json();
                const EPHEMERAL_KEY = data.client_secret.value;

                peerConnection = new RTCPeerConnection();
                await setupAudio();
                setupDataChannel();

                const offer = await peerConnection.createOffer();
                await peerConnection.setLocalDescription(offer);

                const baseUrl = "https://api.openai.com/v1/realtime";
                const model = "gpt-4o-realtime-preview-2024-12-17";
                const sdpResponse = await fetch(`${baseUrl}?model=${model}`, {
                    method: "POST",
                    body: offer.sdp,
                    headers: {
                        Authorization: `Bearer ${EPHEMERAL_KEY}`,
                        "Content-Type": "application/sdp"
                    },
                });

                const answer = {
                    type: "answer",
                    sdp: await sdpResponse.text(),
                };
                await peerConnection.setRemoteDescription(answer);

                updateStatus('Connected');
                stopButton.disabled = false;
                hideError();

            } catch (error) {
                startButton.disabled = false;
                stopButton.disabled = true;
                showError('Error: ' + error.message);
                console.error('Initialization error:', error);
                updateStatus('Failed to connect');
            }
        }

        function stopRecording() {
            if (peerConnection) {
                peerConnection.close();
                peerConnection = null;
            }
            if (audioStream) {
                audioStream.getTracks().forEach(track => track.stop());
                audioStream = null;
            }
            if (dataChannel) {
                dataChannel.close();
                dataChannel = null;
            }
            startButton.disabled = false;
            stopButton.disabled = true;
            updateStatus('Ready to start');
        }

        // -------------------------------------------------------------------------------------------------------------//
        // UI helper functions
        // -------------------------------------------------------------------------------------------------------------//
        function updateStatus(message) {
            statusDiv.textContent = message;
        }

        function showError(message) {
            errorDiv.style.display = 'block';
            errorDiv.textContent = message;
        }

        function hideError() {
            errorDiv.style.display = 'none';
        }

        // -------------------------------------------------------------------------------------------------------------//
        // Event listeners
        // -------------------------------------------------------------------------------------------------------------//
        startButton.addEventListener('click', init);
        stopButton.addEventListener('click', stopRecording);
        document.addEventListener('DOMContentLoaded', () => updateStatus('Ready to start'));
    </script>
</body>
</html>